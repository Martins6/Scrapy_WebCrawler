{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Topic Modelling"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import decomposition\n",
    "import nltk\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'As especulações de que a \\n estaria planejando um remake de \\n não são novas e, para alimentar ainda mais a ideia na cabeça dos fãs, o artista \\n decidiu recriar a vila do jogo com um visual mais atualizado.\\nPara isso, o desenvolvedor usou o motor gráfico Unreal Engine 4 — e o resultado é impressionante! Confira no vídeo em destaque logo acima.\\nAlém disso, Ibarra ainda divulgou imagens dos cenários com um modelo de Leon, também criado no mesmo motor. Veja:\\nÉ possível conferir mais imagens da recriação do artista em sua página no \\nArtStation\\n.\\n foi lançado originalmente em 2005 e foi relançado em diferentes plataformas ao longo dos anos.'"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "corpus_list = []\n",
    "with Path('crawled_data.jl').open() as f:\n",
    "    for line in f:\n",
    "        json_dict = json.loads(line)\n",
    "        corpus_list.append(json_dict['corpus'])\n",
    "corpus = np.array(corpus_list)\n",
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/adriel_martins/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "76 (76, 4844)\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwords[1]\n",
    "vectorizer = CountVectorizer(stop_words=stopwords)\n",
    "vectors = vectorizer.fit_transform(corpus).todense() # (documents, vocab)\n",
    "vectors.shape #, vectors.nnz / vectors.shape[0], row_means.shape\n",
    "print(len(corpus.data), vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['adquirir', 'adquiriu', 'adriana', 'adulta', 'adversária',\n",
       "       'advogada', 'advogado', 'aetherium', 'afasta', 'afastado',\n",
       "       'afastar', 'afastou', 'afeição', 'afetada', 'afetado', 'afiliados',\n",
       "       'afinal', 'afirma', 'afirmando', 'afirmar', 'afirmaram',\n",
       "       'afirmavam', 'afirmou', 'agente', 'agentes', 'agir', 'agora',\n",
       "       'agosto', 'agrada', 'agradece', 'agradecer', 'agressão', 'aguarda',\n",
       "       'aguardado', 'aguardados', 'aguardar', 'agência', 'agências',\n",
       "       'ainda', 'aintenção', 'ajuda', 'ajudando', 'ajudar', 'ajudou',\n",
       "       'ajudá', 'ajustar', 'ajuste', 'akbar', 'akira', 'akiva', 'al',\n",
       "       'aladdin', 'alcances', 'aleatoriamente', 'alegria', 'alemanha',\n",
       "       'alemão', 'alex', 'alexander', 'algo', 'algum', 'alguma',\n",
       "       'algumas', 'alguns', 'alguém', 'ali', 'aliados', 'aliança',\n",
       "       'alienígenas', 'alimentada', 'alimentar', 'alta', 'altamente',\n",
       "       'altas', 'alterado', 'alteração', 'alterá', 'alto', 'altos',\n",
       "       'alucinado', 'alunos', 'alvo', 'alvos', 'além', 'alívio', 'amadas',\n",
       "       'amamos', 'amanda', 'amanhã', 'amantes', 'amarrada', 'amazon',\n",
       "       'amban', 'amber', 'ambicioso', 'ambientada', 'ambientado',\n",
       "       'ambiente', 'ambições', 'ambos'], dtype='<U18')"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "vocab = np.array(vectorizer.get_feature_names())\n",
    "vocab[200:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_words=8\n",
    "\n",
    "def show_topics(a):\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_top_words-1:-1]]\n",
    "    topic_words = ([top_words(t) for t in a])\n",
    "    return [' '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['pode creed assassin valhalla eivor missões assentamento jogo',\n",
       " 'série musical ano high temporada disney school 2ª',\n",
       " 'jogo jogar cada campanha armas ainda jogador além',\n",
       " 'filme netflix ainda novo cenas justamente produção nova',\n",
       " 'the série mandalorian mandaloriano personagem trama através sendo']"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "m,n=vectors.shape\n",
    "d=5  # num topics\n",
    "clf = decomposition.NMF(n_components=d, random_state=1)\n",
    "\n",
    "W1 = clf.fit_transform(vectors)\n",
    "H1 = clf.components_\n",
    "show_topics(H1)"
   ]
  }
 ]
}